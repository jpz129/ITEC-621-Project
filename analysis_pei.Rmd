---
title: "EDA"
author: "Pei-Hsin Lin"
date: "3/30/2021"
output: pdf_document
---

```{r}
library(tidyverse)
```


# Load & clean data
```{r}
data <- read_csv("data/Project_Data_final.csv")
data <- na.omit(data) # remove data row w/ NA
inf <- data$X1[is.infinite(data$pop_density_sqmi)]
data <- data[-inf,]
nrow(data)
names(data)

data <- data[,c(3,4,6,9,19,22,23,24,25,27)] # remove redundant variables
# unique(data$Region) 
unique(data$Division) 
head(data)
```


# EDA

```{r}
# data$Region <- as.numeric(as.factor(data$Region))
data$Division_num <- as.numeric(as.factor(data$Division))
# Regions:
# 1 = Midwest
# 2 = Northeast
# 3 = South
# 4 = West
# 
# Divisions:
# 1 = East North Central
# 2 = East South Central
# 3 = Middle Atlantic
# 4 = Mountain
# 5 = New England
# 6 = Pacific
# 7 = South Atlantic
# 8 = West North Central
# 9 = West South Central

X<-data[,-c(3,10)] # remove date (non-numeric)
names(X)
M<-cor(X)
library(corrplot)
corrplot(M, method="ellipse", tl.cex = 0.3)
corrplot(M, method="number", tl.cex=.8,number.cex=.8,tl.srt=30)
```
```{r}
plot(data$median_listing_price~.,data=X)
```
## log transform
```{r}
names(data)
data[,-c(3,10,11)] %>% 
  mutate_at(1:8, list(log = ~ log(.))) ->
  data_log
data_log <- as.data.frame(Map(function(x) replace(x, is.infinite(x), 0), data_log))
data_log <- data_log[,c(9:16)]# only include the logged variables
data_log <- cbind('date'=data$date,'Division'=data$Division,data_log)
# data_log <- cbind('Division'=data$Division,data_log)
data_log <- na.omit(data_log)
names(data_log)
data_log$Division <- as.factor(data_log$Division)
```

## pairplot
```{r message=F}
library(GGally)
ggpairs(data_log,lower = list(continuous = wrap("points", alpha = 0.05))) # some still skewed..
```

# Model
## Regression
```{r}
lm.fit<-lm(median_listing_price_log~.,data=data_log)
summary(lm.fit) # pop_density_sqmi_log NA due to strong collinearity # high R2
```


## logistic regression
```{r}
data_log$median_listing_price_clas <- data$median_listing_price
mlp_mean <- mean(data_log$median_listing_price_clas)
mlp_std <- sd(data_log$median_listing_price_clas)
ifelse(data_log$median_listing_price_clas > mlp_mean+mlp_std, "High",
       ifelse(data_log$median_listing_price_clas < mlp_mean-mlp_std,"Low","Median")) ->
  data_log$median_listing_price_clas
data_log$median_listing_price_clas <- as.numeric(as.factor(data_log$median_listing_price_clas))
head(data_log)

lm.clas.fit<-lm(median_listing_price_clas~.-median_listing_price_log,data=data_log)
summary(lm.clas.fit) # pop_density_sqmi_log NA due to strong collinearity # low R2
logit.fit <- glm(median_listing_price_clas~.-median_listing_price_log,data=data_log)
summary(logit.fit)
```


## Ridge/LASSO
```{r}
library(glmnet)
set.seed(1)
names(train_data)
x <- model.matrix(median_listing_price_log~.-median_listing_price_clas,data = data_log)[,-1]
y <- data_log$median_listing_price_log 
lasso <- glmnet(x, y, alpha=1) 
set.seed(1)
lasso.cv.10Fold <- cv.glmnet(x,y,alpha=1) 
lasso.best.lambda <- lasso.cv.10Fold$lambda.min 
lasso.min.mse <- min(lasso.cv.10Fold$cvm)
cbind("Best Lambda"=lasso.best.lambda, 
      "Log(Lambda)"=log(lasso.best.lambda), 
      "Best 10FCV MSE" = lasso.min.mse)
lasso.coef <- coef(lasso, s=lasso.best.lambda) 
lasso.coef
```

remove case and pop_dens
final predictors: date, Division, POP_ESTIMATE_2019_log, Median_Household_Income_2019_log, total_listing_count_log, deaths_per_1000_log, county_land_area_log

```{r}
final.reg <- lm(median_listing_price_log ~ date + Division + POP_ESTIMATE_2019_log + Median_Household_Income_2019_log + total_listing_count_log + deaths_per_1000_log + county_land_area_log, data=data_log)
summary(final.reg)
```


## 80/20 split
```{r}
set.seed(123)
train <- sample(nrow(data_log),0.8*nrow(data_log))
train_data <- data_log[train,]
test_data <- data_log[-train,]
nrow(train_data)
nrow(test_data)
```








----------------------------------------
```{r}
library(tidyverse)
data <- read_csv("data/project_data.csv")[,c(2,3,4,5,6,8,11,35)]
data <- na.omit(data)
head(data) # 13804 rows
names(data)
unique(data$date)
# unique(data$county_fips) # 986
unique(data$state) # 51
```

```{r}
summary(data)
```


```{r}
data$region <- 0
for (i in 1:nrow(data)) {
  if (data$state[i] %in% c("connecticut","maine","massachusetts","new hampshire","rhode island", "vermont")) {
    data$region[i] <- 1
  } else if (data$state[i] %in% c("new jersey", "new york", "puerto rico")) {
    data$region[i] <- 2
  } else if (data$state[i] %in% c("delaware", "district of columbia", "maryland", "pennsylvania", "virginia", "west virginia")) {
    data$region[i] <- 3
  } else if (data$state[i] %in% c("alabama", "florida", "georgia", "kentucky", "mississippi", "north carolina", "south carolina", "tennessee")) {
    data$region[i] <- 4
  } else if (data$state[i] %in% c("illinois", "indiana", "michigan", "minnesota", "ohio", "wisconsin")) {
    data$region[i] <- 5
  } else if (data$state[i] %in% c("arkansas", "louisiana", "new mexico", "oklahoma", "texas")) {
    data$region[i] <- 6
  } else if (data$state[i] %in% c("iowa", "kansas", "missouri", "nebraska")) {
    data$region[i] <- 7
  } else if (data$state[i] %in% c("colorado", "montana", "north dakota", "south dakota", "utah", "wyoming")) {
    data$region[i] <- 8
  } else if (data$state[i] %in% c("arizona", "california", "hawaii", "nevada", "american samoa", "guam", "northern mariana islands")) {
    data$region[i] <- 9
  } else if (data$state[i] %in% c( "alaska", "idaho", "oregon", "washington")) {
    data$region[i] <- 10
  }
}
data$region <- as.factor(data$region)
# Region I: Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, Vermont
# Region II: New Jersey, New York, Puerto Rico, US Virgin Islands
# Region III: Delaware, District of Columbia, Maryland, Pennsylvania, Virginia, West Virginia
# Region IV: Alabama, Florida, Georgia, Kentucky, Mississippi, North Carolina, South Carolina, Tennessee
# Region V: Illinois, Indiana, Michigan, Minnesota, Ohio, Wisconsin
# Region VI: Arkansas, Louisiana, New Mexico, Oklahoma, Texas
# Region VII: Iowa, Kansas, Missouri, Nebraska
# Region VIII: Colorado, Montana, North Dakota, South Dakota, Utah, Wyoming
# Region IX: Arizona, California, Hawaii, Nevada, American Samoa, Guam, Northern Mariana Islands
# Region X: Alaska, Idaho, Oregon, Washington
head(data)
```


# EDA
1a. Does the monthly amount of covid cases affect the listing price over states?
- It seems that covid case amount might affect the listing price. 
- We can then build regression model: listing~covid_cases

```{r}
library(ggplot2)
```

```{r}
ggplot(aes(x=cases, y=average_listing_price), data=data) + 
  geom_point() + geom_smooth() 
```

```{r}
ggplot(aes(x=cases, y=average_listing_price), data=data) + 
  geom_point() + geom_smooth() +
  facet_grid(rows = vars(region))
```

1b. Does the monthly amount of death affect the listing price over states?
- It seems that death amount might affect the listing price. 
- We can then build regression model: listing_price~death

```{r}
ggplot(aes(x=deaths, y=average_listing_price), data=data) + 
  geom_point() + geom_smooth() 
```

```{r}
ggplot(aes(x=deaths, y=average_listing_price), data=data) + 
  geom_point() + geom_smooth() +
  facet_grid(rows = vars(region))
```


2. When does the trend of covid start to slow down? 
   Does monthly housing inventory decrease when the covid cases increase?
- Overall, it seems that the covid trend starts to slow down since May 2020, but it starts to increase faster after the end of 2020.
- It seems that monthly housing inventory decreases when the covid cases increase. However, the listing price increases when the covid cases increase.

```{r}
# covid trend over states
ggplot(aes(x=date, y=cases), data=data) +
  geom_jitter() + geom_smooth()
```

```{r}
ggplot(aes(x=date, y=cases), data=data) + 
  geom_point() + geom_smooth() +
  facet_grid(cols = vars(region)) +
  theme(axis.text.x=element_text(angle=45))
```

```{r}
data%>%
  group_by(date,region)%>%
  summarise(Covid_Cases=mean(cases))%>%
  ungroup()%>%
  ggplot(aes(
    x=date,
    y=Covid_Cases,
    colour=region,
    group=region,
    shape=region
    ))+
  geom_line()+
  geom_point(size=4)
```

```{r}
data%>%
  group_by(date,region)%>%
  summarise(alp=mean(average_listing_price))%>%
  ungroup()%>%
  ggplot(aes(
    x=date,
    y=alp,
    colour=region,
    group=region,
    shape=region
    ))+
  geom_line()+
  geom_point(size=4)

data%>%
  group_by(date,region)%>%
  summarise(alc=mean(active_listing_count))%>%
  ungroup()%>%
  ggplot(aes(
    x=date,
    y=alc,
    colour=region,
    group=region,
    shape=region
    ))+
  geom_line()+
  geom_point(size=4)

```
```{r}
data%>%
  group_by(date,region)%>%
  summarise(Covid_Cases=mean(cases), alp=mean(average_listing_price), alc=mean(active_listing_count))%>%
  ungroup()%>%
  ggplot(aes(
        x = Covid_Cases,
        y = alp,
        col = region
        )) +
       geom_point(mapping = aes(size = alp)) +
      geom_point(aes(size = Covid_Cases)) +
      scale_size(range = c(1, 20), guide = FALSE) +
      scale_x_discrete(aes(label = Covid_Cases)) +
      scale_color_brewer(palette = "Set3")

data%>%
  group_by(date,region)%>%
  summarise(Covid_Cases=mean(cases), alp=mean(average_listing_price), alc=mean(active_listing_count))%>%
  ungroup()%>%
  ggplot(aes(
        x = Covid_Cases,
        y = alc,
        col = region
        )) +
       geom_point(mapping = aes(size = alc)) +
      geom_point(aes(size = Covid_Cases)) +
      scale_size(range = c(1, 20), guide = FALSE) +
      scale_x_discrete(aes(label = Covid_Cases)) +
      scale_color_brewer(palette = "Set3")
```

3a. Time series for listing price (Year â†’ Month)
    Can the listing price in months of 2020 be predicted by the former period?    
    - It seems that there is a positive trend for listing price, but we will have to run the time series model. 

```{r}
data%>%
  group_by(date)%>%
  summarise(price=mean(average_listing_price))%>%
  ggplot(aes(
    x=date,
    y=price,
  ))+
  geom_point()+
  geom_line()+
  theme(axis.text.x=element_text(angle=45))
```
 
3b. Regression (listing price prediction)

- We can first see correlation relationship between different variables. Compared to other variables, cases and death have stronger correlation with listing count and price. 

- We also find the correlation between average listing count and average listing price is stronger than other relationships. That means the average number of for sale properties may have effects on the average listing price.

- Surprisingly, county and state do not have strong correlation with other variables, but region does have good positive correlation with listing price.

```{r}
data$region <- as.numeric(data$region)
data$state <- as.numeric(as.factor(data$state))
data$county <- as.numeric(as.factor(data$county))
X<-data[,-1]
M<-cor(X)
library(corrplot)
corrplot(M, method="shade")
corrplot(M, method="number")
```
- Case amount does have significant positive effect on listing price, but it's not that strong.
```{r}
lm.fit<-lm(average_listing_price~cases,data = data)
summary(lm.fit) # has significant influence but really small
```

- Death amount does have significant positive effect on listing price.
```{r}
lm.fit<-lm(average_listing_price~deaths,data = data)
summary(lm.fit) # has significant influence 
```

- Throughout the step method, we get the final model as average_listing_price ~ deaths + county + state + region + active_listing_count. The reason why the case variable is removed might be the strong correlation with deaths variable.
```{r}
full.lm.fit<-lm(average_listing_price~cases+deaths+county+state+region+active_listing_count,data = data)
summary(full.lm.fit)

lm.step<-step(full.lm.fit)
summary(lm.step)
```
- Since it's hard to interpret with 51 states and hundreds of counties, we remove county and state in this time.
```{r}
full.lm.fit<-lm(average_listing_price~deaths+region+active_listing_count,data = data)
summary(full.lm.fit)

lm.step<-step(full.lm.fit)
summary(lm.step)
```

- From the result of reg tree, death is not a factor that could help predict listing price, which means covid does have influence on listing price but the it is not that helpful for prediction. 
```{r}
# Regression Tree Example
library(rpart)

# grow tree
fit <- rpart(average_listing_price ~ deaths + 
    region + active_listing_count,
   method="anova", data=data)

printcp(fit) # display the results
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits

# create additional plots
par(mfrow=c(1,2)) # two plots on one page
rsq.rpart(fit) # visualize cross-validation results  

# plot tree
plot(fit, uniform=TRUE)
text(fit, use.n=TRUE, all=TRUE, cex=.8,
   main="Regression Tree")

# # create attractive postcript plot of tree
# post(fit, file = "tree2.ps",
#    title = "Regression Tree")

# prune the tree
pfit<- prune(fit, cp=0.01) # from cptable   

# plot the pruned tree
plot(pfit, uniform=TRUE,
   main="Pruned Regression Tree")
text(pfit, use.n=TRUE, all=TRUE, cex=.8)
# post(pfit, file = "ptree2.ps",
#    title = "Pruned Regression Tree")
```

 
3c. Classification:
We can then divide monthly listing price into two/three levels (high,medium,low), and see 
how the factors affect the listing price level.
-- logistic regression
-- classification tree
- yearly_listing_price_level ~ covid_case(1/0)
- monthly_listing_price_level ~ covid_case(quant)
- monthly_listing_price_level ~ population(quant or rank)+covid_case(quant)+covid_death
- monthly_listing_price_level ~ state+population(quant or rank)+covid_case(quant)+covid_death

```{r}
# use mean to create categorical variable (Mean of average listing price: 440390)
data$average_listing_price_level <- ifelse(data$average_listing_price > 440390, "1", "0")
data$average_listing_price_level <- as.factor(data$average_listing_price_level)

log.fit <- glm(average_listing_price_level ~ deaths  + 
               region + active_listing_count,
               data=data, family = "binomial")
summary(log.fit)
```

```{r}
set.seed(123)
n<-nrow(data)
train<-sample(n,0.8*n)
log.fit <- glm(average_listing_price_level ~ deaths  + 
    region + active_listing_count,
  data=data[train,], family = "binomial")
summary(log.fit)
```

- It's a good model with high accuracy.
```{r}
library(caret)
test.x<-data[-train,c(3,9,7)]
pred.y<-predict(log.fit,test.x)
pred.y<-ifelse(pred.y > 0.5, "1", "0")
pred.y<-as.factor(pred.y)
y<-data[-train,]$average_listing_price_level
y<-as.factor(y)
confusionMatrix(pred.y,data[-train,]$average_listing_price_level)
```

- classification tree
```{r}
# Classification Tree with rpart
library(rpart)

# grow tree
fit <- rpart(average_listing_price_level ~ deaths  + 
    region + active_listing_count,
   method="class", data=data[train,])

printcp(fit) # display the results
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits

# plot tree
plot(fit, uniform=TRUE,
   main="Classification Tree")
text(fit, use.n=TRUE, all=TRUE, cex=.8)

# # create attractive postscript plot of tree
# post(fit, file = "Classfication_Tree.ps",
#    title = "Classification Tree")

# prune the tree
pfit<- prune(fit, cp=fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"])

# plot the pruned tree
plot(pfit, uniform=TRUE,
   main="Pruned Classification Tree ")
text(pfit, use.n=TRUE, all=TRUE, cex=.8)
# post(pfit, file = "Purn_Classification_Tree.ps",
#    title = "Pruned Classification Tree")

ctree.pred.y<-predict(pfit,test.x)
ctree.pred.y<-as.data.frame(ctree.pred.y)
ctree.pred.y<-ifelse(ctree.pred.y$`0` > 0.5, "1", "0")
ctree.pred.y<-as.factor(ctree.pred.y)
confusionMatrix(ctree.pred.y,y)
```









